{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "StandardCNN-Copy1.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLr7CdwHqv5F"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import scipy.io as sio\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6xdAvU6qv5F"
      },
      "source": [
        "## Load in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnW1WLCYrKwC",
        "outputId": "6adada4d-52e0-4cef-ac3d-0b93187e5a39"
      },
      "source": [
        "!git clone https://github.com/mzhao98/emotion_recognition"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'emotion_recognition' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1v4hUbjrK25"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwfdnNwSqv5F"
      },
      "source": [
        "def load_dataset():\n",
        "    train_dir = 'emotion_recognition/data/train/'\n",
        "    test_dir = 'emotion_recognition/data/test/'\n",
        "    categories = ['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']\n",
        "\n",
        "    train_file_dictionary = {}\n",
        "    train_imagefile_to_class_dictionary = {}\n",
        "    for emotion in categories:\n",
        "        train_file_dictionary[emotion] = []\n",
        "\n",
        "    counter = 0\n",
        "    for i in range(len(categories)):\n",
        "        for subdir, dirs, files in os.walk(train_dir+categories[i]+'/'):\n",
        "            for file in files:\n",
        "                train_file_dictionary[categories[i]].append(train_dir+categories[i]+'/'+file)\n",
        "                train_imagefile_to_class_dictionary[counter] = {}\n",
        "                train_imagefile_to_class_dictionary[counter]['file'] = train_dir+categories[i]+'/'+file\n",
        "                train_imagefile_to_class_dictionary[counter]['label'] = i\n",
        "                counter += 1\n",
        "\n",
        "\n",
        "\n",
        "    test_file_dictionary = {}\n",
        "    test_imagefile_to_class_dictionary = {}\n",
        "    for emotion in categories:\n",
        "        test_file_dictionary[emotion] = []\n",
        "\n",
        "    counter = 0\n",
        "    for i in range(len(categories)):\n",
        "        for subdir, dirs, files in os.walk(test_dir+categories[i]+'/'):\n",
        "            for file in files:\n",
        "                test_file_dictionary[categories[i]].append(test_dir+categories[i]+'/'+file)\n",
        "                test_imagefile_to_class_dictionary[counter] = {}\n",
        "                test_imagefile_to_class_dictionary[counter]['file'] = test_dir+categories[i]+'/'+file\n",
        "                test_imagefile_to_class_dictionary[counter]['label'] = i\n",
        "                counter += 1\n",
        "\n",
        "    return train_imagefile_to_class_dictionary, test_imagefile_to_class_dictionary"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDvQZLMPqv5F"
      },
      "source": [
        "## Create Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHxa_IhYqv5F"
      },
      "source": [
        "class FacialEmotionDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, imagefile_to_class_dictionary, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            imagefile_to_class_dictionary (dictionary): Dictionary of image filenames to class for each emotion.\n",
        "        \"\"\"\n",
        "#         self.root_dir = root_dir\n",
        "        self.imagefile_to_class_dictionary = imagefile_to_class_dictionary\n",
        "        self.transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.Resize((96, 96)),\n",
        "                    transforms.ToTensor(),\n",
        "                    # transforms.CenterCrop(10),\n",
        "                 \n",
        "                 transforms.Normalize((0.5), \n",
        "                                      (0.5))])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imagefile_to_class_dictionary.keys())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "#         print(\"idx\", idx)\n",
        "        path_to_image = self.imagefile_to_class_dictionary[idx]['file']\n",
        "#         image = io.imread(path_to_image)\n",
        "        image = Image.open(path_to_image)\n",
        "        image = self.transform(image).float()\n",
        "        label = int(self.imagefile_to_class_dictionary[idx]['label'])\n",
        "        return image, label"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5fPjSOz9Djy"
      },
      "source": [
        "\n",
        "\n",
        "class FacialEmotionDataset_Augmented(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, imagefile_to_class_dictionary, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            imagefile_to_class_dictionary (dictionary): Dictionary of image filenames to class for each emotion.\n",
        "        \"\"\"\n",
        "#         self.root_dir = root_dir\n",
        "        self.imagefile_to_class_dictionary = imagefile_to_class_dictionary\n",
        "        self.transform = transforms.Compose([\n",
        "                                    \n",
        "\n",
        "        transforms.RandomResizedCrop(96),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5), \n",
        "                                      (0.5)),\n",
        "        transforms.Resize((96, 96)),\n",
        "\n",
        "        \n",
        "    ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imagefile_to_class_dictionary.keys())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "#         print(\"idx\", idx)\n",
        "        path_to_image = self.imagefile_to_class_dictionary[idx]['file']\n",
        "#         image = io.imread(path_to_image)\n",
        "        image = Image.open(path_to_image)\n",
        "        image = self.transform(image).float()\n",
        "        label = int(self.imagefile_to_class_dictionary[idx]['label'])\n",
        "        return image, label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O3zVZVqqv5F"
      },
      "source": [
        "## Create CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzfbLGp1qv5F"
      },
      "source": [
        "class FaceNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceNet, self).__init__()\n",
        "        # torch.Size([256, 1, 64, 64])\n",
        "        # 3 input image channel (RGB), #6 output channels, 4x4 kernel \n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3,3), stride=1, \n",
        "                               padding=1, dilation=1, groups=1, \n",
        "                               bias=True, padding_mode='reflect')\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, \n",
        "                               padding=1, dilation=1, groups=1, \n",
        "                               bias=True, padding_mode='reflect')\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, \n",
        "                               padding=1, dilation=1, groups=1, \n",
        "                               bias=True, padding_mode='reflect')\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(64, 32, kernel_size=(3,3), stride=1, \n",
        "                               padding=1, dilation=1, groups=1, \n",
        "                               bias=True, padding_mode='reflect')\n",
        "        \n",
        "        \n",
        "        self.drop1 = nn.Dropout(p=0.1)\n",
        "        self.norm1 = nn.LayerNorm([48, 48])\n",
        "        self.norm2 = nn.LayerNorm([24, 24])\n",
        "        \n",
        "        self.fc1 = nn.Linear(1152, 256)\n",
        "        self.fc2 = nn.Linear(256, 96)\n",
        "        self.fc3 = nn.Linear(96, 7)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "        x = self.norm1(x)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = self.norm2(x)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
        "\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), (2,2))\n",
        "#         print(x.shape)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop1(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.drop1(x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "#         x = self.drop1(x)\n",
        "        \n",
        "#         output = x\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "        "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlCCYV2xqv5F"
      },
      "source": [
        "train_imagefile_to_class_dictionary, test_imagefile_to_class_dictionary = load_dataset()\n",
        "train_dataset = FacialEmotionDataset(train_imagefile_to_class_dictionary)\n",
        "test_dataset = FacialEmotionDataset(test_imagefile_to_class_dictionary)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDVutmS5qv5F",
        "outputId": "ee9782a4-132e-46d1-9601-baa53086cb44"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrxQMkwOqv5G"
      },
      "source": [
        "def train_model(model, train_dataset, dataloaders, criterion, optimizer, test_data_loader, test_dataset, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    train_acc_history = []\n",
        "    test_acc_history = []\n",
        "    loss_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for batch_idx, (inputs, labels) in enumerate(dataloaders):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders)\n",
        "            \n",
        "            epoch_acc = running_corrects.double() / len(train_dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            if phase == 'val':\n",
        "              test_acc = compute_test_accuray(model, test_data_loader, test_dataset)\n",
        "              if test_acc > best_acc:\n",
        "                  best_acc = test_acc\n",
        "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                test_acc_history.append(test_acc)\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                loss_history.append(epoch_loss)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, best_model_wts, train_acc_history, test_acc_history, loss_history"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyJu_Camqv5G",
        "outputId": "8ae61ad9-0c06-4526-bdce-3e754342e327"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = FaceNet()\n",
        "model_ft = model.to(device)\n",
        "feature_extract = False\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t conv1.weight\n",
            "\t conv1.bias\n",
            "\t conv2.weight\n",
            "\t conv2.bias\n",
            "\t conv3.weight\n",
            "\t conv3.bias\n",
            "\t conv4.weight\n",
            "\t conv4.bias\n",
            "\t norm1.weight\n",
            "\t norm1.bias\n",
            "\t norm2.weight\n",
            "\t norm2.bias\n",
            "\t fc1.weight\n",
            "\t fc1.bias\n",
            "\t fc2.weight\n",
            "\t fc2.bias\n",
            "\t fc3.weight\n",
            "\t fc3.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcP4PlQJxpCJ",
        "outputId": "052b2f39-43de-461b-f8f9-5bee3bfa782e"
      },
      "source": [
        "train_dataset = FacialEmotionDataset(train_imagefile_to_class_dictionary)\n",
        "train_dataset_augmented = FacialEmotionDataset_Augmented(train_imagefile_to_class_dictionary)\n",
        "\n",
        "test_dataset = FacialEmotionDataset(test_imagefile_to_class_dictionary)\n",
        "\n",
        "\n",
        "increased_dataset = torch.utils.data.ConcatDataset([train_dataset_augmented,train_dataset])\n",
        "\n",
        "print(len(increased_dataset))\n",
        "train_data_loader = torch.utils.data.DataLoader(increased_dataset, batch_size=32,\n",
        "                                          shuffle=True,\n",
        "                                         )\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32,\n",
        "                                          shuffle=True,\n",
        "                                         )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BsuyPhIqv5G",
        "outputId": "a4ed4204-9fce-45a7-c667-bb5aa899ead8"
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 100\n",
        "\n",
        "# Train and evaluate\n",
        "model, val_acc_history, best_model_wts, train_acc_history, test_acc_history, loss_history = train_model(model_ft, increased_dataset, train_data_loader, criterion, optimizer_ft, test_data_loader, test_dataset, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 51.6775 Acc: 0.3695\n",
            "val Loss: 50.2221 Acc: 0.3908\n",
            "Test accuracy =  tensor(0.4253, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 49.6049 Acc: 0.3962\n",
            "val Loss: 47.9229 Acc: 0.4233\n",
            "Test accuracy =  tensor(0.4642, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 47.6737 Acc: 0.4264\n",
            "val Loss: 45.4672 Acc: 0.4613\n",
            "Test accuracy =  tensor(0.5098, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 43.9726 Acc: 0.4764\n",
            "val Loss: 42.3566 Acc: 0.4967\n",
            "Test accuracy =  tensor(0.5400, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 42.3280 Acc: 0.4944\n",
            "val Loss: 41.5264 Acc: 0.5023\n",
            "Test accuracy =  tensor(0.5453, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 41.1955 Acc: 0.5064\n",
            "val Loss: 40.2104 Acc: 0.5202\n",
            "Test accuracy =  tensor(0.5538, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 39.9338 Acc: 0.5220\n",
            "val Loss: 38.2738 Acc: 0.5407\n",
            "Test accuracy =  tensor(0.5740, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 39.1345 Acc: 0.5341\n",
            "val Loss: 37.9121 Acc: 0.5466\n",
            "Test accuracy =  tensor(0.5766, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 38.2921 Acc: 0.5409\n",
            "val Loss: 37.0261 Acc: 0.5628\n",
            "Test accuracy =  tensor(0.5769, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 37.4544 Acc: 0.5529\n",
            "val Loss: 36.1265 Acc: 0.5685\n",
            "Test accuracy =  tensor(0.5883, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 36.6807 Acc: 0.5606\n",
            "val Loss: 35.3730 Acc: 0.5855\n",
            "Test accuracy =  tensor(0.5988, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 35.9633 Acc: 0.5718\n",
            "val Loss: 35.1805 Acc: 0.5836\n",
            "Test accuracy =  tensor(0.5911, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 35.3096 Acc: 0.5815\n",
            "val Loss: 33.8725 Acc: 0.6035\n",
            "Test accuracy =  tensor(0.5978, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 34.6682 Acc: 0.5899\n",
            "val Loss: 32.6074 Acc: 0.6203\n",
            "Test accuracy =  tensor(0.6076, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 33.8624 Acc: 0.5994\n",
            "val Loss: 33.3931 Acc: 0.6087\n",
            "Test accuracy =  tensor(0.5913, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 33.3956 Acc: 0.6060\n",
            "val Loss: 31.2820 Acc: 0.6344\n",
            "Test accuracy =  tensor(0.6177, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 32.7357 Acc: 0.6140\n",
            "val Loss: 30.6005 Acc: 0.6449\n",
            "Test accuracy =  tensor(0.6141, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 32.0667 Acc: 0.6221\n",
            "val Loss: 30.9407 Acc: 0.6294\n",
            "Test accuracy =  tensor(0.6116, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 31.5602 Acc: 0.6304\n",
            "val Loss: 29.4666 Acc: 0.6552\n",
            "Test accuracy =  tensor(0.6142, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 30.7479 Acc: 0.6409\n",
            "val Loss: 28.7055 Acc: 0.6660\n",
            "Test accuracy =  tensor(0.6145, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 30.1948 Acc: 0.6488\n",
            "val Loss: 28.2280 Acc: 0.6774\n",
            "Test accuracy =  tensor(0.6126, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 29.7492 Acc: 0.6528\n",
            "val Loss: 27.6866 Acc: 0.6855\n",
            "Test accuracy =  tensor(0.6166, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 29.1246 Acc: 0.6629\n",
            "val Loss: 27.1672 Acc: 0.6898\n",
            "Test accuracy =  tensor(0.6180, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 28.6231 Acc: 0.6681\n",
            "val Loss: 26.7040 Acc: 0.6958\n",
            "Test accuracy =  tensor(0.6123, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 28.3347 Acc: 0.6721\n",
            "val Loss: 25.6540 Acc: 0.7087\n",
            "Test accuracy =  tensor(0.6236, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 27.6389 Acc: 0.6825\n",
            "val Loss: 25.0099 Acc: 0.7180\n",
            "Test accuracy =  tensor(0.6120, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 27.2181 Acc: 0.6857\n",
            "val Loss: 25.0510 Acc: 0.7203\n",
            "Test accuracy =  tensor(0.6183, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 26.9283 Acc: 0.6890\n",
            "val Loss: 25.5129 Acc: 0.7119\n",
            "Test accuracy =  tensor(0.6154, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 26.7133 Acc: 0.6920\n",
            "val Loss: 24.4898 Acc: 0.7210\n",
            "Test accuracy =  tensor(0.6187, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 26.2242 Acc: 0.6963\n",
            "val Loss: 24.9718 Acc: 0.7236\n",
            "Test accuracy =  tensor(0.6123, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 25.8099 Acc: 0.7030\n",
            "val Loss: 24.8034 Acc: 0.7252\n",
            "Test accuracy =  tensor(0.6069, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 25.6564 Acc: 0.7065\n",
            "val Loss: 23.3597 Acc: 0.7344\n",
            "Test accuracy =  tensor(0.6216, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 25.2608 Acc: 0.7126\n",
            "val Loss: 22.9883 Acc: 0.7390\n",
            "Test accuracy =  tensor(0.6181, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 25.1609 Acc: 0.7128\n",
            "val Loss: 22.9558 Acc: 0.7418\n",
            "Test accuracy =  tensor(0.6170, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 24.9070 Acc: 0.7140\n",
            "val Loss: 23.0399 Acc: 0.7395\n",
            "Test accuracy =  tensor(0.6172, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 24.7124 Acc: 0.7166\n",
            "val Loss: 22.7883 Acc: 0.7412\n",
            "Test accuracy =  tensor(0.6191, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 24.5061 Acc: 0.7189\n",
            "val Loss: 22.4959 Acc: 0.7437\n",
            "Test accuracy =  tensor(0.6170, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 24.1620 Acc: 0.7231\n",
            "val Loss: 22.3358 Acc: 0.7468\n",
            "Test accuracy =  tensor(0.6202, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 24.1136 Acc: 0.7243\n",
            "val Loss: 22.2384 Acc: 0.7474\n",
            "Test accuracy =  tensor(0.6284, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 23.7494 Acc: 0.7259\n",
            "val Loss: 22.3008 Acc: 0.7445\n",
            "Test accuracy =  tensor(0.6163, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 40/99\n",
            "----------\n",
            "train Loss: 23.7656 Acc: 0.7273\n",
            "val Loss: 21.9762 Acc: 0.7491\n",
            "Test accuracy =  tensor(0.6226, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 41/99\n",
            "----------\n",
            "train Loss: 23.5638 Acc: 0.7294\n",
            "val Loss: 21.7963 Acc: 0.7499\n",
            "Test accuracy =  tensor(0.6268, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 42/99\n",
            "----------\n",
            "train Loss: 23.2685 Acc: 0.7328\n",
            "val Loss: 22.0224 Acc: 0.7458\n",
            "Test accuracy =  tensor(0.6227, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 43/99\n",
            "----------\n",
            "train Loss: 23.3522 Acc: 0.7311\n",
            "val Loss: 21.9437 Acc: 0.7470\n",
            "Test accuracy =  tensor(0.6116, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 44/99\n",
            "----------\n",
            "train Loss: 23.1070 Acc: 0.7336\n",
            "val Loss: 21.4331 Acc: 0.7544\n",
            "Test accuracy =  tensor(0.6186, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 45/99\n",
            "----------\n",
            "train Loss: 23.1029 Acc: 0.7356\n",
            "val Loss: 21.4240 Acc: 0.7515\n",
            "Test accuracy =  tensor(0.6202, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 46/99\n",
            "----------\n",
            "train Loss: 22.8476 Acc: 0.7363\n",
            "val Loss: 21.3915 Acc: 0.7536\n",
            "Test accuracy =  tensor(0.6294, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 47/99\n",
            "----------\n",
            "train Loss: 22.7395 Acc: 0.7370\n",
            "val Loss: 22.1161 Acc: 0.7456\n",
            "Test accuracy =  tensor(0.6243, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 48/99\n",
            "----------\n",
            "train Loss: 22.6930 Acc: 0.7364\n",
            "val Loss: 21.1987 Acc: 0.7543\n",
            "Test accuracy =  tensor(0.6225, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 49/99\n",
            "----------\n",
            "train Loss: 22.7565 Acc: 0.7374\n",
            "val Loss: 21.1275 Acc: 0.7559\n",
            "Test accuracy =  tensor(0.6248, device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Epoch 50/99\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA4-YH8Q3j0a"
      },
      "source": [
        "plt.plot(range(len(val_acc_history)), val_acc_history)\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVt_rIJZ3buf"
      },
      "source": [
        "torch.save(model.state_dict(), '4layer_cnn_2.pkl')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnGd38GJ3tMo"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"4layer_cnn_2.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMHTDwWXqv5G"
      },
      "source": [
        "train_accuracy = 0\n",
        "for batch_idx, (inputs, labels) in enumerate(train_data_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "   \n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "    # statistics\n",
        "#     running_loss += loss.item() * inputs.size(0)\n",
        "#     print(\"preds\", preds)\n",
        "#     print('labels.data', labels.data)\n",
        "    train_accuracy += torch.sum(preds == labels.data)\n",
        "#     break\n",
        "\n",
        "# epoch_loss = running_loss / len(dataloaders)\n",
        "train_acc = train_accuracy.double() / len(train_dataset)\n",
        "print('Training accuracy = ', train_acc )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkYLB5Xz6qNq"
      },
      "source": [
        "test_accuracy = 0\n",
        "for batch_idx, (inputs, labels) in enumerate(test_data_loader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "  \n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "    # statistics\n",
        "#     running_loss += loss.item() * inputs.size(0)\n",
        "    test_accuracy += torch.sum(preds == labels.data)\n",
        "\n",
        "# epoch_loss = running_loss / len(dataloaders)\n",
        "test_acc = test_accuracy.double() / len(test_dataset)\n",
        "print('Test accuracy = ', test_acc )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaACE5pH2_W-"
      },
      "source": [
        "def compute_test_accuray(model, test_data_loader, test_dataset):\n",
        "  test_accuracy = 0\n",
        "  for batch_idx, (inputs, labels) in enumerate(test_data_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "    \n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "      # statistics\n",
        "  #     running_loss += loss.item() * inputs.size(0)\n",
        "      test_accuracy += torch.sum(preds == labels.data)\n",
        "\n",
        "  # epoch_loss = running_loss / len(dataloaders)\n",
        "  test_acc = test_accuracy.double() / len(test_dataset)\n",
        "  print('Test accuracy = ', test_acc )\n",
        "  return test_acc"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3_tLenF5Vx_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}